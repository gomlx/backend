// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

//go:build amd64 && goexperiment.simd

package nn

import (
	"simd/archsimd"

	"github.com/ajroetker/go-highway/hwy"
)

var SDPAFloat16 func(q []hwy.Float16, k []hwy.Float16, v []hwy.Float16, mask []hwy.Float16, scores []hwy.Float16, output []hwy.Float16, seqLen int, kvLen int, headDim int, scale hwy.Float16)
var SDPABFloat16 func(q []hwy.BFloat16, k []hwy.BFloat16, v []hwy.BFloat16, mask []hwy.BFloat16, scores []hwy.BFloat16, output []hwy.BFloat16, seqLen int, kvLen int, headDim int, scale hwy.BFloat16)
var SDPAFloat32 func(q []float32, k []float32, v []float32, mask []float32, scores []float32, output []float32, seqLen int, kvLen int, headDim int, scale float32)
var SDPAFloat64 func(q []float64, k []float64, v []float64, mask []float64, scores []float64, output []float64, seqLen int, kvLen int, headDim int, scale float64)
var SDPACausalFloat16 func(q []hwy.Float16, k []hwy.Float16, v []hwy.Float16, scores []hwy.Float16, output []hwy.Float16, seqLen int, kvLen int, headDim int, scale hwy.Float16)
var SDPACausalBFloat16 func(q []hwy.BFloat16, k []hwy.BFloat16, v []hwy.BFloat16, scores []hwy.BFloat16, output []hwy.BFloat16, seqLen int, kvLen int, headDim int, scale hwy.BFloat16)
var SDPACausalFloat32 func(q []float32, k []float32, v []float32, scores []float32, output []float32, seqLen int, kvLen int, headDim int, scale float32)
var SDPACausalFloat64 func(q []float64, k []float64, v []float64, scores []float64, output []float64, seqLen int, kvLen int, headDim int, scale float64)

// SDPA computes single-head scaled dot-product attention.
//
//   - q:      [seqLen, headDim] (queries, row-major)
//   - k:      [kvLen, headDim] (keys, row-major)
//   - v:      [kvLen, headDim] (values, row-major)
//   - mask:   [seqLen, kvLen] (additive mask, nil for no mask)
//   - scores: [seqLen, kvLen] (scratch buffer for attention weights)
//   - output: [seqLen, headDim] (result)
//   - scale:  typically 1/sqrt(headDim)
//
// Algorithm: output = softmax(Q@K^T * scale + mask) @ V
//
// This function dispatches to the appropriate SIMD implementation at runtime.
func SDPA[T hwy.Floats](q []T, k []T, v []T, mask []T, scores []T, output []T, seqLen int, kvLen int, headDim int, scale T) {
	switch any(q).(type) {
	case []hwy.Float16:
		SDPAFloat16(any(q).([]hwy.Float16), any(k).([]hwy.Float16), any(v).([]hwy.Float16), any(mask).([]hwy.Float16), any(scores).([]hwy.Float16), any(output).([]hwy.Float16), seqLen, kvLen, headDim, any(scale).(hwy.Float16))
	case []hwy.BFloat16:
		SDPABFloat16(any(q).([]hwy.BFloat16), any(k).([]hwy.BFloat16), any(v).([]hwy.BFloat16), any(mask).([]hwy.BFloat16), any(scores).([]hwy.BFloat16), any(output).([]hwy.BFloat16), seqLen, kvLen, headDim, any(scale).(hwy.BFloat16))
	case []float32:
		SDPAFloat32(any(q).([]float32), any(k).([]float32), any(v).([]float32), any(mask).([]float32), any(scores).([]float32), any(output).([]float32), seqLen, kvLen, headDim, any(scale).(float32))
	case []float64:
		SDPAFloat64(any(q).([]float64), any(k).([]float64), any(v).([]float64), any(mask).([]float64), any(scores).([]float64), any(output).([]float64), seqLen, kvLen, headDim, any(scale).(float64))
	}
}

// SDPACausal computes single-head causal scaled dot-product attention.
// This applies a lower-triangular mask on-the-fly: for position i, only
// keys at positions j <= i + (kvLen - seqLen) are attended to.
//
// Parameters are the same as BaseSDPA except mask is not needed (computed implicitly).
//
// This function dispatches to the appropriate SIMD implementation at runtime.
func SDPACausal[T hwy.Floats](q []T, k []T, v []T, scores []T, output []T, seqLen int, kvLen int, headDim int, scale T) {
	switch any(q).(type) {
	case []hwy.Float16:
		SDPACausalFloat16(any(q).([]hwy.Float16), any(k).([]hwy.Float16), any(v).([]hwy.Float16), any(scores).([]hwy.Float16), any(output).([]hwy.Float16), seqLen, kvLen, headDim, any(scale).(hwy.Float16))
	case []hwy.BFloat16:
		SDPACausalBFloat16(any(q).([]hwy.BFloat16), any(k).([]hwy.BFloat16), any(v).([]hwy.BFloat16), any(scores).([]hwy.BFloat16), any(output).([]hwy.BFloat16), seqLen, kvLen, headDim, any(scale).(hwy.BFloat16))
	case []float32:
		SDPACausalFloat32(any(q).([]float32), any(k).([]float32), any(v).([]float32), any(scores).([]float32), any(output).([]float32), seqLen, kvLen, headDim, any(scale).(float32))
	case []float64:
		SDPACausalFloat64(any(q).([]float64), any(k).([]float64), any(v).([]float64), any(scores).([]float64), any(output).([]float64), seqLen, kvLen, headDim, any(scale).(float64))
	}
}

func init() {
	if hwy.NoSimdEnv() {
		initSdpaFallback()
		return
	}
	if archsimd.X86.AVX512() {
		initSdpaAVX512()
		return
	}
	if archsimd.X86.AVX2() {
		initSdpaAVX2()
		return
	}
	initSdpaFallback()
}

func initSdpaAVX2() {
	SDPAFloat16 = BaseSDPA_avx2_Float16
	SDPABFloat16 = BaseSDPA_avx2_BFloat16
	SDPAFloat32 = BaseSDPA_avx2
	SDPAFloat64 = BaseSDPA_avx2_Float64
	SDPACausalFloat16 = BaseSDPACausal_avx2_Float16
	SDPACausalBFloat16 = BaseSDPACausal_avx2_BFloat16
	SDPACausalFloat32 = BaseSDPACausal_avx2
	SDPACausalFloat64 = BaseSDPACausal_avx2_Float64
}

func initSdpaAVX512() {
	SDPAFloat16 = BaseSDPA_avx512_Float16
	SDPABFloat16 = BaseSDPA_avx512_BFloat16
	SDPAFloat32 = BaseSDPA_avx512
	SDPAFloat64 = BaseSDPA_avx512_Float64
	SDPACausalFloat16 = BaseSDPACausal_avx512_Float16
	SDPACausalBFloat16 = BaseSDPACausal_avx512_BFloat16
	SDPACausalFloat32 = BaseSDPACausal_avx512
	SDPACausalFloat64 = BaseSDPACausal_avx512_Float64
}

func initSdpaFallback() {
	SDPAFloat16 = BaseSDPA_fallback_Float16
	SDPABFloat16 = BaseSDPA_fallback_BFloat16
	SDPAFloat32 = BaseSDPA_fallback
	SDPAFloat64 = BaseSDPA_fallback_Float64
	SDPACausalFloat16 = BaseSDPACausal_fallback_Float16
	SDPACausalBFloat16 = BaseSDPACausal_fallback_BFloat16
	SDPACausalFloat32 = BaseSDPACausal_fallback
	SDPACausalFloat64 = BaseSDPACausal_fallback_Float64
}
